{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d434f6-cac3-4351-aeb0-082515bfa730",
   "metadata": {},
   "source": [
    "Design and implement a machine learning model to perform sentiment analysis on a given\n",
    "dataset containing textual data and corresponding sentiment labels. The analysis should use\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) vectors to transform the text into\n",
    "numerical features and classify the sentiments effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d98830-76bd-4473-8a17-0476ab58af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8b9117-44aa-4d33-ac05-6bd36f4978be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Asad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the necessary models for each task\n",
    "nltk.download('punkt')  # Download the tokenizer models\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')  # Download WordNet, required for semantic analysis for lemmatization\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')  # Download POS tagger\n",
    "nltk.download('omw-1.4')  # Download the WordNet OMW corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a610293f-bba5-4e11-b99a-9f19776a436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae416af-f06a-454e-964e-5e0cc07cabc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27481, 10), (3534, 9))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8a79fe-106c-47a2-a848-0f77cc325e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0caf0fc1-ebca-4033-98ac-8444dc89bdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
       "0       morning        0-20  Afghanistan          38928346         652860.0   \n",
       "1          noon       21-30      Albania           2877797          27400.0   \n",
       "2         night       31-45      Algeria          43851044        2381740.0   \n",
       "3       morning       46-60      Andorra             77265            470.0   \n",
       "4          noon       60-70       Angola          32866272        1246700.0   \n",
       "\n",
       "   Density (P/Km²)  \n",
       "0               60  \n",
       "1              105  \n",
       "2               18  \n",
       "3              164  \n",
       "4               26  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa275a97-fc7f-48de-a6e2-f6c0df40d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            3534 non-null   object \n",
      " 1   text              3534 non-null   object \n",
      " 2   sentiment         3534 non-null   object \n",
      " 3   Time of Tweet     3534 non-null   object \n",
      " 4   Age of User       3534 non-null   object \n",
      " 5   Country           3534 non-null   object \n",
      " 6   Population -2020  3534 non-null   int64  \n",
      " 7   Land Area (Km²)   3534 non-null   float64\n",
      " 8   Density (P/Km²)   3534 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 248.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdebfbfb-e680-47b6-9976-4b32466adb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            27481 non-null  object \n",
      " 1   text              27480 non-null  object \n",
      " 2   selected_text     27480 non-null  object \n",
      " 3   sentiment         27481 non-null  object \n",
      " 4   Time of Tweet     27481 non-null  object \n",
      " 5   Age of User       27481 non-null  object \n",
      " 6   Country           27481 non-null  object \n",
      " 7   Population -2020  27481 non-null  int64  \n",
      " 8   Land Area (Km²)   27481 non-null  float64\n",
      " 9   Density (P/Km²)   27481 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b56cde1-0cb5-467a-86dd-ea41928adc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['selected_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f9faef-8f3e-4084-a2be-3718e5c6db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            27481 non-null  object \n",
      " 1   text              27480 non-null  object \n",
      " 2   sentiment         27481 non-null  object \n",
      " 3   Time of Tweet     27481 non-null  object \n",
      " 4   Age of User       27481 non-null  object \n",
      " 5   Country           27481 non-null  object \n",
      " 6   Population -2020  27481 non-null  int64  \n",
      " 7   Land Area (Km²)   27481 non-null  float64\n",
      " 8   Density (P/Km²)   27481 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0153f458-99bb-4768-b5b1-d8ddff687987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27481, 9), (3534, 9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccfe2c9-4c53-4658-ba40-51d8ee0975c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     1430\n",
       "positive    1103\n",
       "negative    1001\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60c26a5-eb60-4c8f-8dbe-92c53d2b39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable='ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba9a91-bb0a-4ebf-b276-fd67817bd960",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b284c0a-cf8c-462e-bb12-efd66ced1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-string values\n",
    "train['text'] = train['text'].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with None (NaN)\n",
    "train.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90eb3132-2441-45bd-997f-0569b5cd1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-string values\n",
    "test['text'] = test['text'].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with None (NaN)\n",
    "test.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7909cb73-7024-4a9b-b859-a8817f310d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test['sentiment'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee44c6e6-1f07-40a8-af32-87b484f56374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(texts):\n",
    "    # lemmatize the tokens and store them in a list\n",
    "    processed_texts = []\n",
    "    for doc in nlp.pipe(texts, n_process=-1):\n",
    "        lemmatized_tokens = [token.lemma_.lower() for token in doc if token.is_alpha and token.lemma_ not in nlp.Defaults.stop_words]\n",
    "        \n",
    "        # Join the lemmatized tokens into a string\n",
    "        processed_text = \" \".join(lemmatized_tokens)\n",
    "        \n",
    "        processed_texts.append(processed_text)\n",
    "        \n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b5f0783-8512-4b41-a5f8-561b2d046a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text'] = train['text'].astype(str)\n",
    "#test['text'] =test['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b71e83-4402-481c-8493-7bd32807a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprcoess_text function to user_review column\n",
    "train['text'] = preprocess_text(train['text'])\n",
    "test['text'] = preprocess_text(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a163f9d-bf9f-4c57-84ac-840f232088c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    respond i\n",
       "1    sooo sad i miss san diego\n",
       "2                 boss bully i\n",
       "3            interview leave i\n",
       "4              son release buy\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the first 5 rows\n",
    "train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b81895af-4a65-4c6f-9116-fc9ecbecad27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          session day\n",
       "1    shanghai exciting precisely skyscraper galore ...\n",
       "2    recession hit veronique branquinho quit compan...\n",
       "3                                           happy bday\n",
       "4                                               i like\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea14c7c-6ee4-47ca-a07c-414ead2eb1a1",
   "metadata": {},
   "source": [
    "### Vectorization & One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b27762a-4270-4e1c-adee-09018a80caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_ohe = CountVectorizer(min_df=0.001, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaeea170-2743-4eac-94d7-ee86cf461eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_transform user_review\n",
    "count_vectorizer_ohe_train = count_vectorizer_ohe.fit_transform(train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596fe1a8-0506-4f55-949c-21553fae90a9",
   "metadata": {},
   "source": [
    "### Building a Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c620b380-b261-482e-985d-69923b5b48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "naive_bayes_classifier = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f2b6c0e-b6d4-47f8-b872-a225de38b4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976346433770014"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the train data\n",
    "naive_bayes_classifier.fit(count_vectorizer_ohe_train, train['sentiment'])\n",
    "naive_bayes_classifier.score(count_vectorizer_ohe_train, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49a37c6d-4373-4171-8928-d49fc6931f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6844934917940011"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create the naive bayes model for the validation data\n",
    "count_vectorizer_ohe_test = count_vectorizer_ohe.transform(test['text'])\n",
    "naive_bayes_classifier.score(count_vectorizer_ohe_test, test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c238f8d-a449-4961-be06-d81b9c82e83f",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd6f5d13-8398-45b1-9d7f-2a5a4b5eab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize count_vectorizer and name it count_vectorizer\n",
    "count_vectorizer = CountVectorizer(min_df=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a0cc1a-139e-4e6f-8baf-d54a7c8f2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_transform user_review\n",
    "count_vectorizer_train = count_vectorizer.fit_transform(train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742b9e0-0e25-4444-9c32-d6ce8cd9f6ae",
   "metadata": {},
   "source": [
    "### Building a Naive Bayes Model using count vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ab72f-010b-44c0-9003-b31faed82590",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "naive_bayes_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c040f895-ba16-4c29-80ee-0c421db9f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976346433770014"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the train data\n",
    "naive_bayes_classifier.fit(count_vectorizer_train, train['sentiment'])\n",
    "naive_bayes_classifier.score(count_vectorizer_train, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0c1a61c-3515-4dce-9a25-ae30598dbc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4046406338426712"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create the naive bayes model for the validation data\n",
    "count_vectorizer_test = count_vectorizer.transform(test['sentiment'])\n",
    "naive_bayes_classifier.score(count_vectorizer_test, test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40204910-e122-4ee2-ac81-738e5e9f8af0",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b05df0e3-43e4-417d-b68d-7220e28d298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tfifd vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3724a560-13db-424a-88ac-21245e2e7990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976346433770014"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the train data using tfidf\n",
    "tfidf_vectorizer_train = tfidf_vectorizer.fit_transform(train['text'])\n",
    "naive_bayes_classifier.fit(tfidf_vectorizer_train, train['sentiment'])\n",
    "naive_bayes_classifier.score(tfidf_vectorizer_train, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b24e7905-c83c-4267-914b-0c333e1ab80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976346433770014"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the validation data using tfidf\n",
    "tfidf_vectorizer_test = tfidf_vectorizer.transform(train['text'])\n",
    "naive_bayes_classifier.score(tfidf_vectorizer_test, train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ebe61-3cd0-486d-81ac-55b6a1606bc5",
   "metadata": {},
   "source": [
    "### Using n-grams with Tfldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8fb60ba-d101-4e11-87eb-124653529592",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ngram_vectorizer = TfidfVectorizer(min_df=0.001, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418ebc0-2b78-4806-ba90-aedfef870297",
   "metadata": {},
   "source": [
    "### Building Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbbf6102-6633-48ff-b6fb-d5976f648131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915574963609898"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the train data using tfidf and ngram\n",
    "tfidf_ngram_vectorizer_train = tfidf_ngram_vectorizer.fit_transform(train['text'])\n",
    "naive_bayes_classifier.fit(tfidf_ngram_vectorizer_train, train['sentiment'])\n",
    "naive_bayes_classifier.score(tfidf_ngram_vectorizer_train, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abc92c86-6746-4f2f-b142-319a55f6f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['couple', 'course', 'cousin', 'cover', 'coz', 'crash', 'crazy',\n",
       "       'cream', 'cross', 'cry'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram_vectorizer.get_feature_names_out()[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "566417bd-0324-450d-b097-78828075f2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6760045274476514"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the validation data using tfidf and ngram\n",
    "tfidf_ngram_vectorizer_test = tfidf_ngram_vectorizer.transform(test['text'])\n",
    "naive_bayes_classifier.score(tfidf_ngram_vectorizer_test, test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "128d7fc4-8e6a-4753-a1fe-3de435d0ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ngram_vectorizer = CountVectorizer(min_df=0.001, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5da6ad1d-f1b4-4280-abde-4ced4e781644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915574963609898"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the train data using count vectorizer and ngram\n",
    "count_ngram_vectorizer_train = count_ngram_vectorizer.fit_transform(train['text'])\n",
    "naive_bayes_classifier.fit(count_ngram_vectorizer_train, train['sentiment'])\n",
    "naive_bayes_classifier.score(count_ngram_vectorizer_train, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1a4c66d-fa39-49a1-bc55-5270756c18b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6760045274476514"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the naive bayes model for the validation data using count vectorizer and ngram\n",
    "count_ngram_vectorizer_test = count_ngram_vectorizer.transform(test['text'])\n",
    "naive_bayes_classifier.score(count_ngram_vectorizer_test, test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007a4a0-d8ef-4092-8688-3ffc83b1f250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
